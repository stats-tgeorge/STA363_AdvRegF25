{
  "hash": "80a28d440b186513053d33fe20e3fa8b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Poisson Regression\"\nsubtitle: \"BMLR Chapter 4\"\nformat: \n  revealjs:\n    output-file: \"04_poisson_ch4.html\"\n    slide-number: true\n  html:\n    output-file: \"04_poisson_ch4_o.html\"\nlogo: \"../img/favicon.png\"\n---\n\n\n\n\n## Setup\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(GGally)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(viridis)\nlibrary(ggfortify)\nlibrary(gridExtra)\n```\n:::\n\n\n\n\n## Learning goals (1/2) {.smaller}\n\n- Describe properties of the Poisson random variable\n\n- Write the Poisson regression model \n\n- Describe how the Poisson regression differs from least-squares regression\n\n- Interpret the coefficients for the Poisson regression model \n\n- Compare two Poisson regression models\n\n- Define and calculate residuals for the Poisson regression model \n\n- Use Goodness-of-fit to assess model fit \n\n## Learning goals (2/2) {.smaller}\n\n- Identify overdispersion \n\n- Apply modeling approaches to deal with overdispersion \n\n- Explore properties of negative binomial versus Poisson response \n\n- Fit and interpret models with offset to adjust for differences in sampling effort\n\n- Fit and interpret Zero-inflated Poisson models\n\n- Write likelihood for Poisson and Zero-inflated Poisson model\n\n\n## Scenarios to use Poisson regression{.smaller}\n\n- Does the number of employers conducting on-campus interviews during a year differ for public and private colleges?\n\n- Does the daily number of asthma-related visits to an Emergency Room differ depending on air pollution indices?\n\n- Does the number of paint defects per square foot of wall differ based on the years of experience of the painter? \n\n. . .\n\nEach response variable is a count per a unit of time or space.\n\n\n\n## Poisson distribution {.smaller}\n\nLet $Y$ be the number of events in a given unit of time or space. Then $Y$ can be modeled using a *Poisson distribution*\n\n. . .\n\n$$P(Y=y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\hspace{10mm} y=0,1,2,\\ldots, \\infty$$\n\n\n\n## Poisson Features {.smaller}\n\n- $E(Y) = Var(Y) = \\lambda$ \n- The distribution is typically skewed right, particularly if $\\lambda$ is small\n- The distribution becomes more symmetric as $\\lambda$ increases\n  - If $\\lambda$ is sufficiently large, it can be approximated using a normal distribution ([Click here](https://online.stat.psu.edu/stat414/lesson/28/28.2) for an example.)\n  \n\n## Poisson Graphs  {.smaller}\n\n:::{.panel-tabset}\n\n### Graphs\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n\n\n\n### Table\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> Mean </th>\n   <th style=\"text-align:right;\"> Variance </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> lambda = 1 </td>\n   <td style=\"text-align:right;\"> 0.99351 </td>\n   <td style=\"text-align:right;\"> 0.9902178 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda = 5 </td>\n   <td style=\"text-align:right;\"> 4.99367 </td>\n   <td style=\"text-align:right;\"> 4.9865798 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> lambda = 50 </td>\n   <td style=\"text-align:right;\"> 49.99288 </td>\n   <td style=\"text-align:right;\"> 49.8962683 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n  \n:::\n\n## Example {.smaller}\n\nThe annual number of earthquakes registering at least 2.5 on the Richter Scale and having an epicenter within 40 miles of downtown Memphis follows a Poisson distribution with mean 6.5. **What is the probability there will be at 3 or fewer such earthquakes next year?**\n\n. . .\n\n$$P(Y \\leq 3) = P(Y = 0) + P(Y = 1) + P(Y = 2) + P(Y = 3)$$\n\n\n$$ = \\frac{e^{-6.5}6.5^0}{0!} + \\frac{e^{-6.5}6.5^1}{1!} + \\frac{e^{-6.5}6.5^2}{2!} + \\frac{e^{-6.5}6.5^3}{3!}$$\n\n$$ = 0.112$$\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppois(3, 6.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1118496\n```\n\n\n:::\n:::\n\n\n\n\n\n\n::: aside\nExample adapted from [Introduction to Probability Theory Example 28-2](https://online.stat.psu.edu/stat414/lesson/28/28.2)\n:::\n\n\n\n# Poisson regression\n## Poisson regression{.smaller}\n\n**The data: Household size in the Philippines**\n\n<br> \n\nThe data [fHH1.csv](data/fHH1.csv) come from the 2015 Family Income and Expenditure Survey conducted by the Philippine Statistics Authority. \n\n**Goal**: Understand the association between household size and various characteristics of the household\n\n**Response**: \n- `total`: Number of people in the household other than the head\n\n:::: {.columns}\n::: {.column}\n\n**Predictors**: \n- `location`: Where the house is located\n- `age`: Age of the head of household\n- `roof`: Type of roof on the residence (proxy for wealth)\n\n:::\n\n::: {.column}\n\n\n**Other variables**: \n- `numLT5`: Number in the household under 5 years old \n\n:::\n::::\n\n## The data {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhh_data <- read_csv(\"data/fHH1.csv\")\nhh_data |> slice(1:5) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|location     | age| total| numLT5|roof                          |\n|:------------|---:|-----:|------:|:-----------------------------|\n|CentralLuzon |  65|     0|      0|Predominantly Strong Material |\n|MetroManila  |  75|     3|      0|Predominantly Strong Material |\n|DavaoRegion  |  54|     4|      0|Predominantly Strong Material |\n|Visayas      |  49|     3|      0|Predominantly Strong Material |\n|MetroManila  |  74|     3|      0|Predominantly Strong Material |\n\n\n:::\n:::\n\n\n\n\n\n\n## Response variable\n\n\n:::: {.columns}\n::: {.column width=\"80%\"}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n\n\n:::\n\n::: {.column}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|  mean|   var|\n|-----:|-----:|\n| 3.685| 5.534|\n\n\n:::\n:::\n\n\n\n\n:::\n::::\n\n\n## Why the least-squares model doesn't work {.smaller}\n\nThe goal is to model $\\lambda$, the expected number of people in the household (other than the head), as a function of the predictors (covariates)\n\n. . .\n\nWe might be tempted to try a linear model $$\\lambda_i = \\beta_0 + \\beta_1x_{i1} + \\beta_2x_{i2} + \\dots + \\beta_px_{ip}$$\n\n. . .\n\nThis model won't work because...\n\n- It could produce negative values of $\\lambda$ for certain values of the predictors \n- The equal variance assumption required to conduct inference for linear regression is violated. \n\n\n\n## Poisson regression model {.smaller}\n\nIf $Y_i \\sim Poisson$ with $\\lambda = \\lambda_i$ for the given values $x_{i1}, \\ldots, x_{ip}$, then \n\n\n$$\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip}$$\n\n\n- Each observation can have a different value of $\\lambda$ based on its value of the predictors $x_1, \\ldots, x_p$\n\n- $\\lambda$ determines the mean and variance, so we don't need to estimate a separate error term \n\n\n\n## Poisson vs. multiple linear regression \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Regression models: Linear regression (left) and Poisson regression (right).](04_poisson_ch4_files/figure-revealjs/OLSpois-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n::: aside\nFrom [BMLR Figure 4.1](https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html#a-graphical-look-at-poisson-regression)\n:::\n\n\n\n## Assumptions for Poisson regression {.smaller}\n\n:::: {.columns}\n::: {.column}\n\n**Poisson response**: The response variable is a count per unit of time or space, described by a Poisson distribution, at each level of the predictor(s)\n\n**Independence**: The observations must be independent of one another\n\n**Mean = Variance**: The mean must equal the variance\n\n**Linearity**: The log of the mean rate, $\\log(\\lambda)$, must be a linear function of the predictor(s)\n\n:::\n\n::: {.column}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-8-1.png){width=100%}\n:::\n:::\n\n\n\n\n:::\n::::\n\n\n## Model 1: Number in household vs. age {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- glm(total ~ age, data = hh_data, family = poisson)\n\ntidy(model1) |> \n  kable(digits = 4)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   1.5499|    0.0503|   30.8290|       0|\n|age         |  -0.0047|    0.0009|   -5.0258|       0|\n\n\n:::\n:::\n\n\n\n\n$$\\log(\\hat{\\lambda}) = 1.5499  - 0.0047 ~ age$$\n\n\n. . .\n\nQuestion: The coefficient for `age` is -0.0047. Interpret this coefficient in context.\n\n## Answers {.smaller}\n\n- Each additional year older the head of household is, the estimated average log of the number of people in the household is .0047 lower. \n\n- Each additional year older the head of household is, the estimated average number of people in the household reduces by 0.5%.\n- Each additional year older the head of household is the estimated average number of people in the household changes by a factor of .995.\n\n- For every 10 years older the head of household is, the estimated average number of people in the household reduces by 5%.\n\n\n## Understanding the interpretation \n\nLet's derive the change in predicted mean when we go from $x$ to $x+1$ \n\n(see boardwork)\n\n\n## Is the coefficient of `age` statistically significant? {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |   1.5499|    0.0503|   30.8290|       0|   1.4512|    1.6482|\n|age         |  -0.0047|    0.0009|   -5.0258|       0|  -0.0065|   -0.0029|\n\n\n:::\n:::\n\n\n\n\n$$H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs. } \\hspace{2mm} H_a: \\beta_1 \\neq 0$$\n\n. . .\n\n**Test statistic**\n\n$$Z = \\frac{\\hat{\\beta}_1 - 0}{SE(\\hat{\\beta}_1)} = \\frac{-0.0047 - 0}{0.0009} = -5.026 \\text{ (using exact values)}$$\n\n. . .\n\n**P-value**\n\n$$P(|Z| > |-5.026|) = 5.01 \\times 10^{-7} \\approx 0$$ \n\n\n\n## What are plausible values for the coefficient of `age`? {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |   1.5499|    0.0503|   30.8290|       0|   1.4512|    1.6482|\n|age         |  -0.0047|    0.0009|   -5.0258|       0|  -0.0065|   -0.0029|\n\n\n:::\n:::\n\n\n\n\n**95% confidence interval for the coefficient of `age`**\n\n$$\\hat{\\beta}_1 \\pm Z^{*}\\times SE(\\hat{\\beta}_1)$$\n$$-0.0047 \\pm 1.96 \\times 0.0009 = \\mathbf{(-.0065, -0.0029)}$$\n\n. . .\n\n\nQuestion: Interpret the interval in terms of the change in mean household size. \n\n## **Which can best help us determine whether Model 1 is a good fit?**\n\n:::{.panel-tabset}\n\n### Plots\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(data = hh_data, aes(x = age, y = total)) + \n  geom_point() + \n  labs(y = \"Total household size\", \n       title = \"Plot A\")\n\np2 <- hh_data |>\n  group_by(age) |> \n  summarise(mean = mean(total)) |>\n  ggplot(aes(x = age, y = mean))+ \n  geom_point() + \n  labs(y = \"Empirical mean household size\", \n       title = \"Plot B\")\n\np3 <- hh_data |>\n  group_by(age) |> \n  summarise(log_mean = log(mean(total))) |>\n  ggplot(aes(x = age, y = log_mean)) + \n  geom_point() + \n  labs(y = \"Log empirical mean household size\", \n       title = \"Plot C\")\n\np1 + p2 + p3 + plot_annotation(tag_levels = 'A')\n```\n:::\n\n\n\n\n:::\n\n## Model 2: Add a quadratic effect for `age`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhh_data <- hh_data |> \n  mutate(age2 = age*age)\n\nmodel2 <- glm(total ~ age + age2, data = hh_data, family = poisson)\ntidy(model2, conf.int = T) |> \n  kable(digits = 4)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |  -0.3325|    0.1788|   -1.8594|   0.063|  -0.6863|    0.0148|\n|age         |   0.0709|    0.0069|   10.2877|   0.000|   0.0575|    0.0845|\n|age2        |  -0.0007|    0.0001|  -11.0578|   0.000|  -0.0008|   -0.0006|\n\n\n:::\n:::\n\n\n\n\n\n\n## Model 2: Add a quadratic effect for `age` {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |  -0.3325|    0.1788|   -1.8594|   0.063|  -0.6863|    0.0148|\n|age         |   0.0709|    0.0069|   10.2877|   0.000|   0.0575|    0.0845|\n|age2        |  -0.0007|    0.0001|  -11.0578|   0.000|  -0.0008|   -0.0006|\n\n\n:::\n:::\n\n\n\n\nWe can determine whether to keep $age^2$ in the model in two ways: \n\n1️⃣ Use the p-value (or confidence interval) for the coefficient (since we are adding a single term to the model)\n\n2️⃣ Conduct a drop-in-deviance test\n\n\n\n## Deviance {.smaller}\n\nA **deviance** is a way to measure how the observed data deviates from the model predictions.\n\n- It's a measure unexplained variability in the response variable (similar to SSE in linear regression ) \n\n- Lower deviance means the model is a better fit to the data \n\n. . .\n\nWe can calculate the \"deviance residual\" for each observation in the data (more on the formula later). Let $(\\text{deviance residual}_i$ be the deviance residual for the $i^{th}$ observation, then \n\n$$\\text{deviance} = \\sum(\\text{deviance residual})_i^2$$\n\n. . .\n\n*Note: Deviance is also known as the \"residual deviance\"*\n\n\n\n## Drop-in-Deviance Test {.smaller}\n\nWe can use a **drop-in-deviance test** to compare two models. To conduct the test \n\n1️⃣ Compute the deviance for each model \n\n2️⃣ Calculate the drop in deviance \n\n$$\\text{drop-in-deviance =  Deviance(reduced model) - Deviance(larger model)}$$\n\n. . .\n\n3️⃣ Given the reduced model is the true model $(H_0 \\text{ true})$, then $$\\text{drop-in-deviance} \\sim \\chi_d^2$$\n\nwhere $d$ is the difference in degrees of freedom between the two models (i.e., the difference in number of terms)\n\n## Drop-in-deviance - Model1 and Model2 {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(model1, model2, test = \"Chisq\") |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n| Resid. Df| Resid. Dev| Df| Deviance| Pr(>Chi)|\n|---------:|----------:|--:|--------:|--------:|\n|      1498|   2337.089| NA|       NA|       NA|\n|      1497|   2200.944|  1|  136.145|        0|\n\n\n:::\n:::\n\n\n\n\n. . .\n\nQuestions:\n\n- Write the null and alternative hypotheses.\n- What does the value 2337.089\ttell you? \n- What does the value 1 tell you? \n- What is your conclusion? \n\n\n## Add `location` to the model? {.smaller}\n\nSuppose we want to add `location` to the model, so we compare the following models: \n\n**Model A**: $\\lambda_i = \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2$\n\n**Model B**: $\\lambda_i =  \\beta_0 + \\beta_1 ~ age_i + \\beta_2 ~ age_i^2 + \\beta_3 ~ Loc1_i + \\beta_4 ~ Loc2_i + \\beta_5 ~ Loc3_i + \\beta_6 ~ Loc4_i$\n\n## Question {.smaller}\n\nWhich of the following are reliable ways to determine if `location` should be added to the model? \n\n. . .\n\n- Drop-in-deviance test \n- Use the p-value for each coefficient\n- Likelihood ratio test\n- Nested F Test\n- BIC\n\n## Add `location` to the model? {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3 <- glm(total ~ age + age2 + location, data = hh_data, family = poisson)\n```\n:::\n\n\n\n\n. . .\n\nUse a **drop-in-deviance** test to determine if Model 2 or Model 3 (with location) is a better fit for the data.\n\n. . .\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(model2, model3, test = \"Chisq\") |>\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n| Resid. Df| Resid. Dev| Df| Deviance| Pr(>Chi)|\n|---------:|----------:|--:|--------:|--------:|\n|      1497|   2200.944| NA|       NA|       NA|\n|      1493|   2187.800|  4|   13.144|    0.011|\n\n\n:::\n:::\n\n\n\n\nThe p-value is small (0.01 < 0.05), so we conclude that Model 3 is a better fit for the data. \n\n\n\n## Model 3 {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                 | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:--------------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)          |  -0.3843|    0.1821|   -2.1107|  0.0348|  -0.7444|   -0.0306|\n|age                  |   0.0704|    0.0069|   10.1900|  0.0000|   0.0569|    0.0840|\n|age2                 |  -0.0007|    0.0001|  -10.9437|  0.0000|  -0.0008|   -0.0006|\n|locationDavaoRegion  |  -0.0194|    0.0538|   -0.3605|  0.7185|  -0.1250|    0.0859|\n|locationIlocosRegion |   0.0610|    0.0527|    1.1580|  0.2468|  -0.0423|    0.1641|\n|locationMetroManila  |   0.0545|    0.0472|    1.1542|  0.2484|  -0.0378|    0.1473|\n|locationVisayas      |   0.1121|    0.0417|    2.6853|  0.0072|   0.0308|    0.1945|\n\n\n:::\n:::\n\n\n\n\n. . .\n\n**Does this model sufficiently explain the variability in the mean household size?**\n\n\n\n# Goodness-of-fit\n\n\n\n## Pearson residuals {.smaller}\n\nWe can calculate two types of residuals for Poisson regression: Pearson residuals and deviance residuals  \n\n. . .\n\n\n$$\\text{Pearson residual}_i = \\frac{\\text{observed} - \\text{predicted}}{\\text{std. error}} = \\frac{y_i - \\hat{\\lambda}_i}{\\sqrt{\\hat{\\lambda}_i}}$$\n\n\n. . .\n\n- Similar interpretation as standardized residuals from linear regression \n\n- Expect most to fall between -2 and 2\n\n- Used to calculate overdispersion parameter\n\n\n\n## Deviance residuals {.smaller}\n\nThe **deviance residual** indicates how much the observed data deviates from the fitted model\n\n\n$$\\text{deviance residual}_i = \\text{sign}(y_i - \\hat{\\lambda}_i)\\sqrt{2\\Bigg[y_i\\log\\bigg(\\frac{y_i}{\\hat{\\lambda}_i}\\bigg) - (y_i - \\hat{\\lambda}_i)\\Bigg]}$$\n\nwhere \n\n$$\\text{sign}(y_i - \\hat{\\lambda}_i)  =  \\begin{cases}\n1 & \\text{ if }(y_i - \\hat{\\lambda}_i) > 0 \\\\\n-1 & \\text{ if }(y_i - \\hat{\\lambda}_i) < 0 \\\\\n0 & \\text{ if }(y_i - \\hat{\\lambda}_i) = 0\n\\end{cases}$$\n\n\n\n\n## Model 3: Residual plots  {.smaller}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_aug_pearson <- augment(model3, type.residuals = \"pearson\") \nmodel3_aug_deviance <- augment(model3, type.residuals = \"deviance\")\n```\n:::\n\n\n\n\n:::{.panel-tabset}\n\n### Plots\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n\n### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(data = model3_aug_pearson, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Pearson residuals\", \n       title = \"Pearson residuals vs. fitted\")\n\np2 <-  ggplot(data = model3_aug_deviance, aes(x = .fitted, y = .resid)) + \n  geom_point()  + \n  geom_smooth() + \n  labs(x = \"Fitted values\", \n       y = \"Deviance residuals\", \n       title = \"Deviance residuals vs. fitted\")\n\np1 + p2\n```\n:::\n\n\n\n\n:::\n\n\n## Goodness-of-fit {.smaller}\n\n- **Goal**: Use the (residual) deviance to assess how much the predicted values differ from the observed values. Recall $(\\text{deviance}) = \\sum_{i=1}^{n}(\\text{deviance residual})_i^2$\n\n- If the model sufficiently fits the data, then \n\n$$\\text{deviance} \\sim \\chi^2_{df}$$ \n\nwhere $df$ is the model's residual degrees of freedom\n\n. . .\n\n\n- **Question**: What is the probability of observing a deviance larger than the one we've observed, given this model sufficiently fits the data?\n\n. . .\n\n$$P(\\chi^2_{df} > \\text{ deviance})$$\n\n\n\n## Model 3: Goodness-of-fit calculations {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3$deviance\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2187.8\n```\n\n\n:::\n\n```{.r .cell-code}\nmodel3$df.residual\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1493\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npchisq(model3$deviance, model3$df.residual, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.153732e-29\n```\n\n\n:::\n:::\n\n\n\n\nThe probability of observing a deviance greater than 2187.8 is $\\approx 0$, so there is significant evidence of **lack-of-fit**. \n\n\n\n## Lack-of-fit {.smaller}\n\nThere are a few potential reasons for lack-of-fit:\n\n- Missing important interactions or higher-order terms\n\n- Missing important variables (perhaps this means a more comprehensive data set is required)\n\n- There could be extreme observations causing the deviance to be larger than expected (assess based on the residual plots)\n\n- There could be a problem with the Poisson model \n  - May need more flexibility in the model to handle **overdispersion**\n  \n\n\n## Overdispersion  {.smaller}\n\n**Overdispersion**: There is more variability in the response than what is implied by the Poisson model \n\n:::{.panel-tabset}\n\n### Tables\n\n:::: {.columns}\n\n::: {.column}\n\n**Overall**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|  mean|   var|\n|-----:|-----:|\n| 3.685| 5.534|\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.column}\n\n**by Location**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|location     |  mean|   var|\n|:------------|-----:|-----:|\n|CentralLuzon | 3.402| 4.152|\n|DavaoRegion  | 3.390| 4.723|\n|IlocosRegion | 3.586| 5.402|\n|MetroManila  | 3.707| 4.863|\n|Visayas      | 3.902| 6.602|\n\n\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhh_data |>\n  summarise(mean = mean(total), var = var(total)) |>\n  kable(digits = 3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhh_data |>\n  group_by(location) |>\n  summarise(mean = mean(total), var = var(total)) |>\n  kable(digits = 3)\n```\n:::\n\n\n\n\n:::\n\n## Why overdispersion matters {.smaller}\n\nIf there is overdispersion, then there is more variation in the response than what's implied by a Poisson model. This means \n\n❌  The standard errors of the model coefficients are artificially small \n\n❌  The p-values are artificially small \n\n❌  This could lead to models that are more complex than what is needed \n\n. . .\n\nWe can take overdispersion into account by\n\n  - inflating standard errors by multiplying them by a dispersion factor\n  - using a negative-binomial regression model\n\n\n\n\n\n# Quasi-poission \n## Dispersion parameter  {.smaller}\n\nThe **dispersion parameter** is represented by $\\phi$\n\n\n$$\\hat{\\phi} =\\frac{\\text{deviance}}{\\text{residual df}} = \\frac{\\sum_{i=1}^{n}(\\text{Pearson residuals})^2}{n - p}$$\n\nwhere $p$ is the number of terms in the model (including the intercept)\n\n\n- If there is no overdispersion $\\hat{\\phi} = 1$\n\n- If there is overdispersion $\\hat{\\phi} >  1$\n\n\n\n## Accounting for dispersion in the model  {.smaller}\n\nWe inflate the standard errors of the coefficient by multiplying the variance by $\\hat{\\phi}$\n\n. . .\n\n$$SE_{Q}(\\hat{\\beta}) = \\sqrt{\\hat{\\phi}}  * SE(\\hat{\\beta})$$\n- \"Q\" stands for **quasi-Poisson**, since this is an ad-hoc solution \n  - The process for model building and model comparison is called **quasilikelihood** (similar to likelihood without exact underlying distributions)\n\n\n\n\n## Model 3: Quasi-Poisson model  {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel3_q <- glm(total ~ age + age2 + location, data = hh_data, \n                family = quasipoisson) #<<\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                 | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:--------------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)          |  -0.3843|    0.2166|   -1.7744|  0.0762|  -0.8134|    0.0358|\n|age                  |   0.0704|    0.0082|    8.5665|  0.0000|   0.0544|    0.0866|\n|age2                 |  -0.0007|    0.0001|   -9.2000|  0.0000|  -0.0009|   -0.0006|\n|locationDavaoRegion  |  -0.0194|    0.0640|   -0.3030|  0.7619|  -0.1451|    0.1058|\n|locationIlocosRegion |   0.0610|    0.0626|    0.9735|  0.3304|  -0.0620|    0.1837|\n|locationMetroManila  |   0.0545|    0.0561|    0.9703|  0.3320|  -0.0552|    0.1649|\n|locationVisayas      |   0.1121|    0.0497|    2.2574|  0.0241|   0.0156|    0.2103|\n\n\n:::\n:::\n\n\n\n\n\n## Poisson vs. Q-Poisson {.smaller}\n\n:::: {.columns}\n\n::: {.column}\n\n**Poisson**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                 | estimate| std.error|\n|:--------------------|--------:|---------:|\n|(Intercept)          |  -0.3843|    0.1821|\n|age                  |   0.0704|    0.0069|\n|age2                 |  -0.0007|    0.0001|\n|locationDavaoRegion  |  -0.0194|    0.0538|\n|locationIlocosRegion |   0.0610|    0.0527|\n|locationMetroManila  |   0.0545|    0.0472|\n|locationVisayas      |   0.1121|    0.0417|\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.column}\n\n**Quasi-Poisson**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| estimate| std.error|\n|--------:|---------:|\n|  -0.3843|    0.2166|\n|   0.0704|    0.0082|\n|  -0.0007|    0.0001|\n|  -0.0194|    0.0640|\n|   0.0610|    0.0626|\n|   0.0545|    0.0561|\n|   0.1121|    0.0497|\n\n\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n\n\n## Q-Poisson: Inference for coefficients {.smaller}\n\n:::: {.columns}\n\n::: {.column}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                 | estimate| std.error|\n|:--------------------|--------:|---------:|\n|(Intercept)          |  -0.3843|    0.2166|\n|age                  |   0.0704|    0.0082|\n|age2                 |  -0.0007|    0.0001|\n|locationDavaoRegion  |  -0.0194|    0.0640|\n|locationIlocosRegion |   0.0610|    0.0626|\n|locationMetroManila  |   0.0545|    0.0561|\n|locationVisayas      |   0.1121|    0.0497|\n\n\n:::\n:::\n\n\n\n\n:::\n\n::: {.column}\n\n**Test statistic**\n$$t = \\frac{\\hat{\\beta} - 0}{SE_{Q}(\\hat{\\beta})} \\sim t_{n-p}$$\n\n:::\n\n::::\n\n\n\n\n\n\n# Negative binomial regression model \n## Negative binomial regression model  {.smaller}\n\nAnother approach to handle overdispersion is to use a **negative binomial regression model** \n\n- This has more flexibility than the quasi-Poisson model, because there is a new parameter in addition to $\\lambda$\n\n<br> \n\n. . .\n\nLet $Y$ be a **negative binomial random variable**, $Y\\sim NegBinom(r, p)$, then \n\n$$P(Y = y_i) = {y_i + r - 1 \\choose r - 1}(1-p)^{y_i}p^r \\hspace{5mm} y_i = 0, 1, 2, \\ldots, \\infty$$\n\n\n\n## Negative binomial regression model  {.smaller}\n\n- **Main idea**: Generate a $\\lambda$ for each observation (household) and generate a count using the Poisson random variable with parameter $\\lambda$ \n  - Makes the counts more dispersed than with a single parameter \n  \n- Think of it as a Poisson model such that $\\lambda$ is also random \n\n. . .\n\n$\\begin{aligned} &\\text{If }Y|\\lambda \\sim Poisson(\\lambda)\\\\\n&\\text{ and } \\lambda \\sim Gamma\\bigg(r, \\frac{1-p}{p}\\bigg)\\\\\n&\\text{ then } Y \\sim NegBinom(r, p)\\end{aligned}$\n\n\n## Negative binomial regression in R {.smaller}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nmodel3_nb <- glm.nb(total ~ age + age2 + location, data = hh_data)\ntidy(model3_nb) |> \n  kable(digits = 4)\n```\n\n::: {.cell-output-display}\n\n\n|term                 | estimate| std.error| statistic| p.value|\n|:--------------------|--------:|---------:|---------:|-------:|\n|(Intercept)          |  -0.3753|    0.2076|   -1.8081|  0.0706|\n|age                  |   0.0699|    0.0079|    8.8981|  0.0000|\n|age2                 |  -0.0007|    0.0001|   -9.5756|  0.0000|\n|locationDavaoRegion  |  -0.0219|    0.0625|   -0.3501|  0.7262|\n|locationIlocosRegion |   0.0577|    0.0615|    0.9391|  0.3477|\n|locationMetroManila  |   0.0562|    0.0551|    1.0213|  0.3071|\n|locationVisayas      |   0.1104|    0.0487|    2.2654|  0.0235|\n\n\n:::\n:::\n\n\n\n\n# Offsets\n## Data: Airbnbs in NYC {.smaller}\n\nThe data set [NYCairbnb-sample.csv](data/NYCairbnb-sample.csv) contains information about a random sample of 1000 Airbnbs in New York City. It is a subset of the data on 40628 Airbnbs scraped by Awad et al. (2017).\n\n**Variables**\n\n- `number_of_reviews`: Number of reviews for the unit on Airbnb (proxy for number of rentals)\n- `price`: price per night in US dollars\n- `room_type`: Entire home/apartment, private room, or shared room\n- `days`: Number of days the unit has been listed (date when info scraped - date when unit first listed on Airbnb)\n\n\n::: aside\nData set pulled from BMLR Section 4.11.3.\n:::\n\n\n## Data: Airbnbs in NYC {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairbnb <- read_csv(\"data/NYCairbnb-sample.csv\") |>\n  dplyr::select(id, number_of_reviews, days, room_type, price)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|       id| number_of_reviews| days|room_type       | price|\n|--------:|-----------------:|----:|:---------------|-----:|\n| 15756544|                16| 1144|Private room    |   120|\n| 14218251|                15|  471|Private room    |    89|\n|    21644|                 0| 2600|Private room    |    89|\n| 13667835|                 1|  283|Entire home/apt |   150|\n|   265912|                 0| 1970|Entire home/apt |    89|\n\n\n:::\n:::\n\n\n\n\n**Goal**: Use the price and room type of Airbnbs to describe variation in the number of reviews (a proxy for number of rentals).\n\n\n\n## EDA {.smaller}\n\n:::{.panel-tabset}\n\n### Plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-37-1.png){width=960}\n:::\n:::\n\n\n\n\n### Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(data = airbnb, aes(x = number_of_reviews)) + \n  geom_histogram() + \n   labs(x = \"Number of reviews\",\n    title = \"Distribution of number of reviews\")\n\np2 <- airbnb |>\n  filter(price <= 2000) |>\n  group_by(price) |>\n  summarise(log_mean = log(mean(number_of_reviews))) |>\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean #  of reviews vs. price\", \n    subtitle = \"Airbnbs $2000 or less\")\n\np3 <- airbnb |>\n  filter(price <= 500) |>\n  group_by(price) |>\n  summarise(log_mean = log(mean(number_of_reviews))) |>\n  ggplot(aes(x = price, y = log_mean)) + \n  geom_point(alpha= 0.7) + \n  geom_smooth() + \n  labs(x = \"Price in  US dollars\",\n    y = \"Log(mean # reviews)\", \n    title = \"Log mean # of reviews vs. price\", \n    subtitle = \"Airbnbs $500 or less\")\n\np1  / (p2 + p3) \n```\n:::\n\n\n\n\n:::\n\n\n## EDA  {.smaller}\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n\n**Overall** \n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|   mean|     var|\n|------:|-------:|\n| 15.916| 765.969|\n\n\n:::\n:::\n\n\n\n\n\n:::\n\n::: {.column}\n\n**by Room type**\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|room_type       |   mean|     var|\n|:---------------|------:|-------:|\n|Entire home/apt | 16.283| 760.348|\n|Private room    | 15.608| 786.399|\n|Shared room     | 15.028| 605.971|\n\n\n:::\n:::\n\n\n\n\n:::\n::::\n\n\n\n## Considerations for modeling {.smaller}\n\nWe would like to fit the Poisson regression model\n\n$$\\log(\\lambda) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2$$\n\n. . .\n\nQuestion: \n- Based on the EDA, what are some potential issues we may want to address in the model building? \n\n- Suppose any model fit issues are addressed. What are some potential limitations to the conclusions and interpretations from the model? \n\n\n\n\n\n## Offset  {.smaller}\n\n- Sometimes counts are not directly comparable because the observations differ based on some characteristic directly related to the counts, i.e. the *sampling effort*.\n\n- An **offset** can be used to adjust for differences in sampling effort. \n\n. . .\n\n- Let $x_{offset}$ be the variable that accounts for differences in sampling effort, then $\\log(x_{offset})$ will be added to the model.\n\n. . .\n\n$\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ x_{i1} + \\beta_2 ~ x_{i2} + ... + \\beta_p ~ x_{ip} + \\log(x_{offset_i})$\n\n- The offset is a term in the model with coefficient always equal to 1.\n\n\n\n## Adding an offset to the Airbnb model  {.smaller}\n\nWe will add the offset $\\log(days)$ to the model. This accounts for the fact that we would expect Airbnbs that have been listed longer to have more reviews. \n\n$$\\log(\\lambda_i) = \\beta_0 + \\beta_1 ~ price_i + \\beta_2 ~ room\\_type1_i + \\beta_3 ~ room\\_type2_i + \\log(days_i)$$\n<br>\n\n\n**Note:** The response variable for the model is still  $\\log(\\lambda_i)$, the log mean number of reviews\n\n\n\n## Detail on the offset {.smaller}\n\nWe want to adjust for the number of days, so we are interested in $\\frac{reviews}{days}$.\n\n. . .\n\nGiven $\\lambda$ is the mean number of reviews\n\n$$\\log\\Big(\\frac{\\lambda}{days}\\Big) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2$$\n\n. . .\n\n$$\\Rightarrow \\log({\\lambda}) - \\log(days) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2$$\n\n. . .\n\n$$\\Rightarrow \\log({\\lambda}) = \\beta_0 + \\beta_1 ~ price + \\beta_2 ~ room\\_type1 + \\beta_3 ~ room\\_type2 + \\log(days)$$\n\n\n\n## Airbnb model in R {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairbnb_model <- glm(number_of_reviews ~ price + room_type, \n                    data = airbnb, family = poisson, \n                    offset = log(days)) #<<\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                  | estimate| std.error| statistic| p.value|\n|:---------------------|--------:|---------:|---------:|-------:|\n|(Intercept)           |  -4.1351|    0.0170| -243.1397|       0|\n|price                 |  -0.0005|    0.0001|   -7.0952|       0|\n|room_typePrivate room |  -0.0994|    0.0174|   -5.6986|       0|\n|room_typeShared room  |   0.2436|    0.0452|    5.3841|       0|\n\n\n:::\n:::\n\n\n\n\n. . .\n\nThe coefficient for $\\log(days)$ is fixed at 1, so it is not in the model output. \n\n\n\n\n## Interpretations {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term                  | estimate| std.error| statistic| p.value|\n|:---------------------|--------:|---------:|---------:|-------:|\n|(Intercept)           |  -4.1351|    0.0170| -243.1397|       0|\n|price                 |  -0.0005|    0.0001|   -7.0952|       0|\n|room_typePrivate room |  -0.0994|    0.0174|   -5.6986|       0|\n|room_typeShared room  |   0.2436|    0.0452|    5.3841|       0|\n\n\n:::\n:::\n\n\n\n\n<br> \n\nQuestion: \n\n- Interpret the coefficient of `price`. \n- Interpret the coefficient of  `room_typePrivate room`\n\n\n\n\n## Goodness-of-fit {.smaller}\n\n$$\\begin{aligned}&H_0: \\text{ The model is a good fit for the data}\\\\\n&H_a: \\text{ There is significant lack of fit}\\end{aligned}$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npchisq(airbnb_model$deviance, airbnb_model$df.residual, lower.tail = F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\nThere is evidence of significant lack of fit in the model. Therefore, more models would need to be explored that address the issues mentioned earlier. \n\n. . .\n\n*In practice we would assess goodness-of-fit and finalize the model <b>before</b> any interpretations and conclusions.*\n\n\n\n\n\n# Zero-inflated Poisson model\n## Data: Weekend drinking  {.smaller}\n\nThe data [`weekend-drinks.csv`](data/weekend-drinks.csv) contains information from a survey of 77 students in a introductory statistics course on a dry campus. \n\n**Variables** \n\n- `drinks`: Number of drinks they had in the past weekend \n- `off_campus`: 1 - lives off campus, 0 otherwise\n- `first_year`: 1 - student is a first-year, 0 otherwise\n- `sex`: f - student identifies as female, m - student identifies as male \n\n. . .\n\n**Goal**: The goal is explore factors related to drinking behavior on a dry campus.\n\n::: aside\nCase study in BMLR - Section 4.10\n:::\n\n\n## EDA: Response variable {.smaller}\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-46-1.png){width=80%}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Observed vs. expected response {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_poisson_ch4_files/figure-revealjs/unnamed-chunk-48-1.png){width=80%}\n:::\n:::\n\n\n\n\n. . .\n\n**What does it mean to be a \"zero\" in this data?**\n\n\n\n## Two types of zeros {.smaller}\n\nThere are two types of zeros\n\n- Those who happen to have a zero in the data set (people who drink but happened to not drink last weekend)\n- Those who will always report a value of zero (non-drinkers)\n   - These are called **true zeros** \n\n. . .\n\nWe introduce a new parameter $\\alpha$ for the proportion of true zeros,  then fit a model that has two components:\n\n. . .\n\n\n1️⃣ The association between mean number of drinks and various characteristics among those who drink \n\n2️⃣ The estimated proportion of non-drinkers\n\n\n## Zero-inflated Poisson model {.smaller}\n\n**Zero-inflated Poisson (ZIP)** model has two parts\n\n. . .\n\n1️⃣ Association, among those who drink, between the mean number of drinks and predictors sex and off campus residence\n\n. . .\n\n$$\\log(\\lambda) = \\beta_0 + \\beta_1 ~ off\\_campus + \\beta_2 ~ sex$$\nwhere $\\lambda$ is the mean number of drinks among those who drink\n\n. . .\n\n2️⃣ Probability that a student does not drink\n\n$$\\text{logit}(\\alpha) = \\log\\Big(\\frac{\\alpha}{1- \\alpha}\\Big) = \\beta_0 + \\beta_1 ~ first\\_year$$\n\nwhere $\\alpha$ is the proportion of non-drinkers\n\n. . .\n\n**Note:** The same variables can be used in each component\n\n\n\n## Details of the ZIP model {.smaller}\n\n- The ZIP model is a special case of a **latent variable model**\n  - A type of **mixture model** where observations for one or more groups occur together but the group membership unknown\n\n- Zero-inflated models are a common type of mixture model; they apply beyond Poisson regression\n\n\n\n## ZIP model in R \n\nFit ZIP models using the `zeroinfl` function from the **pscl** R package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl)\n\ndrinks_zip <- zeroinfl(drinks ~ off_campus + sex | first_year,\n                data = drinks)\ndrinks_zip\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nzeroinfl(formula = drinks ~ off_campus + sex | first_year, data = drinks)\n\nCount model coefficients (poisson with log link):\n(Intercept)   off_campus         sexm  \n     0.7543       0.4159       1.0209  \n\nZero-inflation model coefficients (binomial with logit link):\n(Intercept)   first_year  \n    -0.6036       1.1364  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Tidy output {.smaller}\n\nUse the `tidy` function from the  **poissonreg** package for tidy model output.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(poissonreg)\n```\n:::\n\n\n\n\n. . .\n\n**Mean number of drinks among those who drink**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(drinks_zip, type = \"count\") %>% kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        |type  | estimate| std.error| statistic| p.value|\n|:-----------|:-----|--------:|---------:|---------:|-------:|\n|(Intercept) |count |    0.754|     0.144|     5.238|   0.000|\n|off_campus  |count |    0.416|     0.206|     2.021|   0.043|\n|sexm        |count |    1.021|     0.175|     5.827|   0.000|\n\n\n:::\n:::\n\n\n\n\n\n\n## Tidy output\n\n**Proportion of non-drinkers**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(drinks_zip, type = \"zero\") %>% kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        |type | estimate| std.error| statistic| p.value|\n|:-----------|:----|--------:|---------:|---------:|-------:|\n|(Intercept) |zero |   -0.604|     0.311|    -1.938|   0.053|\n|first_year  |zero |    1.136|     0.610|     1.864|   0.062|\n\n\n:::\n:::\n\n\n\n\n\n## Interpreting the model coefficients {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        |type  | estimate| std.error| statistic| p.value|\n|:-----------|:-----|--------:|---------:|---------:|-------:|\n|(Intercept) |count |    0.754|     0.144|     5.238|   0.000|\n|off_campus  |count |    0.416|     0.206|     2.021|   0.043|\n|sexm        |count |    1.021|     0.175|     5.827|   0.000|\n\n\n:::\n:::\n\n\n\n\n<br> \n\nQuestions\n\n- Interpret the intercept.\n- Interpret the coefficients of `off_campus` and `sexm`.\n\n## Estimated proportion zeros {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|term        |type | estimate| std.error| statistic| p.value|\n|:-----------|:----|--------:|---------:|---------:|-------:|\n|(Intercept) |zero |   -0.604|     0.311|    -1.938|   0.053|\n|first_year  |zero |    1.136|     0.610|     1.864|   0.062|\n\n\n:::\n:::\n\n\n\n\nQuestions:\n\nBased on the model...\n\n- What is the probability a first-year student is a non-drinker?\n- What is the probability a upperclass student (sophomore, junior, senior) is a non-drinker?\n\n\n## These are just a few of the many models... {.smaller}\n\n- Use the [Vuong Test](https://bookdown.org/roback/bookdown-BeyondMLR/ch-poissonreg.html#the-vuong-test-optional) to compare the fit of the ZIP model to a regular Poisson model\n  - Why can't we use a drop-in-deviance test?\n\n- We've just discussed the ZIP model here, but there are other model applications beyond the standard Poisson regression model (e.g., hurdle models, Zero-inflated Negative Binomial models, etc. )\n\n\n\n# Likelihoods for Poisson models \n## Estimating coefficients in Poisson model {.smaller}\n\n- Least squares estimation would not work because the normality and equal variance assumptions don't hold for Poisson regression \n\n- **Maximum likelihood estimation** is used to estimate the coefficients of Poisson regression. \n\n- The likelihood is the product of the probabilities for the $n$ *<u>independent</u>* observations in the data \n\n## Likelihood for regular Poisson model {.smaller}\n\nLet's go back to example about **household size** in the Philippines. We will focus on the model using the main effect of age to understand variability in mean household size. \n\n. . .\n\nSuppose the first five observations have household sizes of 4, 2, 8, 6, and 1. Then the likelihood is \n\n. . .\n\n$L = \\frac{e^{-\\lambda_1}\\lambda_1^4}{4!} * \\frac{e^{-\\lambda_2}\\lambda_2^2}{2!} * \\frac{e^{-\\lambda_3}\\lambda_3^8}{8!} * \n\\frac{e^{-\\lambda_4}\\lambda_4^6}{6!} * \\frac{e^{-\\lambda_5}\\lambda_5^1}{1!}$\n\n## Likelihood for regular Poisson model {.smaller}\n\n\nWe will use the log likelihood to make finding the MLE easier \n\n. . .\n\n$\\begin{aligned}\\log(L) &= -\\lambda_1 + 4\\log(\\lambda_1) - \\lambda_2 + 2\\log(\\lambda_2) - \\lambda_3 + 8\\log(\\lambda_3)\\\\ & -\\lambda_4 + 6 \\log(\\lambda_4) - \\lambda_5 + \\log(\\lambda_5) + C \\end{aligned}$\n\nwhere \n  - $\\lambda$ is the mean number in household depending on $x_i$\n  - $C = -[\\log(4!) + \\log(2!) + \\log(8!) + \\log(6!)+ \\log(1!)]$\n\n\n\n## Likelihood for regular Poisson model {.smaller}\n\nGiven the age of the head of the household, we fit the model \n\n$$\\log(\\lambda_i) = \\beta_0 + \\beta_1~age_i$$\n\nThen we replace each $\\lambda_i$ in $\\log(L)$ with $e^{\\beta_0 + \\beta_1~age_i}$. \n\n. . .\n\nSuppose the first five observations have ages $X = (32, 21, 55, 44, 28)$. Then\n\n. . .\n\n$$\\begin{aligned} \\log(L) &= [-e^{\\beta_0 + \\beta_132}+ 4(\\beta_0 + \\beta_1 32)] + [ - e^{\\beta_0 + \\beta_121} + 2(\\beta_0 + \\beta_121)] \\\\ &+  [- e^{\\beta_0 + \\beta_155} + 8(\\beta_0 + \\beta_155)] +  [-e^{\\beta_0 + \\beta_144} + 6(\\beta_0 + \\beta_144)] \\\\ &+ [-e^{\\beta_0 + \\beta_128}(\\beta_0 + \\beta_128)] + C \\end{aligned}$$\n\n. . .\n\nUse search algorithm to find the values of $\\beta_0$ and $\\beta_1$ that maximize the above equation. \n\n\n\n## Probabilities under ZIP model {.smaller}\n\nThere are three different types of observations in the data:\n\n- Observed zero and will always be 0 (true zeros)\n- Observed 0 but will not always be 0\n- Observed non-zero count and will not always be 0\n\n\n\n## Probabilities under ZIP model {.smaller}\n\n**True zeros**\n\n$$P(0 | \\text{true zero})= \\alpha$$\n\n. . .\n\n**Observed 0 but will not always be 0**\n\n$$P(0 | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^0}{0!}$$\n\n. . .\n\n**Did not observe 0 and will not always be 0**\n\n$$P(z_i | \\text{not always zero}) = (1 - \\alpha)\\frac{e^{-\\lambda}\\lambda^{z_i}}{z_i!}$$\n\n\n\n## Probabilities under ZIP model {.smaller}\n\nPutting this all together. Let $y_i$ be an observed response then \n\n$$P(Y_i = y_i | x_i) = \\begin{cases}\n\\alpha + (1 - \\alpha)e^{-\\lambda_i} && \\text{ if } y_i = 0 \\\\\n(1 - \\alpha)\\frac{e^{-\\lambda_i}\\lambda_i^{y_i}}{y_i!} && \\text{ if } y_i > 0\n\\end{cases}$$\n\n. . .\n\nRecall from our example, \n\n$$\\lambda_i = e^{\\beta_0 + \\beta_1~off\\_campus_i + \\beta_2 ~ sex_i}$$\n\n$$\\alpha_i = \\frac{e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}{1 + e^{\\beta_{0\\alpha} + \\beta_{1\\alpha} ~ first\\_year_i}}$$\n\n- Plug in $\\lambda_i$ and $\\alpha_i$ into the above equation obtain the likelihood function\n\n\n\n## Acknowledgements\n\nThese slides are based on content in [BMLR: Chapter 4](https://bookdown.org/roback/bookdown-BeyondMLR/)\n\nInitial versions of the slides are by Dr. Maria Tackett, Duke University\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}